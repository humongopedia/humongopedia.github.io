[{"text":"Free Online Books","link":"#free-online-books","contents":[{"text":"Deep Learning","link":"http://www.iro.umontreal.ca/~bengioy/dlbook/"},{"text":"Neural Networks and Deep Learning","link":"http://neuralnetworksanddeeplearning.com/"},{"text":"Deep Learning","link":"http://research.microsoft.com/pubs/209355/DeepLearning-NowPublishing-Vol7-SIG-039.pdf"},{"text":"Deep Learning Tutorial","link":"http://deeplearning.net/tutorial/deeplearning.pdf"},{"text":"neuraltalk","link":"https://github.com/karpathy/neuraltalk"},{"text":"An introduction to genetic algorithms","link":"https://svn-d1.mpi-inf.mpg.de/AG1/MultiCoreLab/papers/ebook-fuzzy-mitchell-99.pdf"},{"text":"Artificial Intelligence: A Modern Approach","link":"http://aima.cs.berkeley.edu/"},{"text":"Deep Learning in Neural Networks: An Overview","link":"http://arxiv.org/pdf/1404.7828v4.pdf"}]},{"text":"Courses","link":"#courses","contents":[{"text":"Machine Learning - Stanford","link":"https://class.coursera.org/ml-005"},{"text":"Machine Learning - Caltech","link":"http://work.caltech.edu/lectures.html"},{"text":"Machine Learning - Carnegie Mellon","link":"http://www.cs.cmu.edu/~tom/10701_sp11/lectures.shtml"},{"text":"Neural Networks for Machine Learning","link":"https://class.coursera.org/neuralnets-2012-001"},{"text":"Neural networks class","link":"https://www.youtube.com/playlist?list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH"},{"text":"Deep Learning Course","link":"http://cilvr.cs.nyu.edu/doku.php?id=deeplearning:slides:start"},{"text":"A.I - Berkeley","link":"https://courses.edx.org/courses/BerkeleyX/CS188x_1/1T2013/courseware/"},{"text":"A.I - MIT","link":"http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/lecture-videos/"},{"text":"Vision and learning - computers and brains","link":"http://web.mit.edu/course/other/i2course/www/vision_and_learning_fall_2013.html"},{"text":"Convolutional Neural Networks for Visual Recognition - Stanford","link":"http://vision.stanford.edu/teaching/cs231n/syllabus_winter2015.html"},{"text":"Convolutional Neural Networks for Visual Recognition - Stanford","link":"http://vision.stanford.edu/teaching/cs231n/syllabus.html"},{"text":"Deep Learning for Natural Language Processing - Stanford","link":"http://cs224d.stanford.edu/"},{"text":"Neural Networks - usherbrooke","link":"http://info.usherbrooke.ca/hlarochelle/neural_networks/content.html"},{"text":"Machine Learning - Oxford","link":"https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/"},{"text":"Deep Learning - Nvidia","link":"https://developer.nvidia.com/deep-learning-courses"},{"text":"https://www.youtube.com/playlist?list=PLHyI3Fbmv0SdzMHAy0aN59oYnLy5vyyTA","link":"https://www.youtube.com/playlist?list=PLHyI3Fbmv0SdzMHAy0aN59oYnLy5vyyTA"},{"text":"Deep Learning - Udacity/Google","link":"https://www.udacity.com/course/deep-learning--ud730"},{"text":"Deep Learning - UWaterloo","link":"https://www.youtube.com/playlist?list=PLehuLRPyt1Hyi78UOkMPWCGRxGcA9NVOE"},{"text":"Statistical Machine Learning - CMU","link":"https://www.youtube.com/watch?v=azaLcvuql_g&list=PLjbUi5mgii6BWEUZf7He6nowWvGne_Y8r"},{"text":"Deep Learning Course","link":"https://www.college-de-france.fr/site/en-yann-lecun/course-2015-2016.htm"},{"text":"Bay area DL school","link":"http://www.bayareadlschool.org/"},{"text":"How To Create A Mind","link":"https://www.youtube.com/watch?v=RIkxVci-R4k"},{"text":"Deep Learning, Self-Taught Learning and Unsupervised Feature Learning","link":"https://www.youtube.com/watch?v=n1ViNeWhC24"},{"text":"Recent Developments in Deep Learning","link":"https://www.youtube.com/watch?v=vShMxxqtDDs&index=3&list=PL78U8qQHXgrhP9aZraxTT5-X1RccTcUYT"},{"text":"The Unreasonable Effectiveness of Deep Learning","link":"https://www.youtube.com/watch?v=sc-KbuZqGkI"},{"text":"Deep Learning of Representations","link":"https://www.youtube.com/watch?v=4xsVFLnHC_0"},{"text":"Principles of Hierarchical Temporal Memory","link":"https://www.youtube.com/watch?v=6ufPpZDmPKA"},{"text":"Machine Learning Discussion Group - Deep Learning w/ Stanford AI Lab","link":"https://www.youtube.com/watch?v=2QJi0ArLq7s&list=PL78U8qQHXgrhP9aZraxTT5-X1RccTcUYT"},{"text":"Making Sense of the World with Deep Learning","link":"http://vimeo.com/80821560"},{"text":"Demystifying Unsupervised Feature Learning ","link":"https://www.youtube.com/watch?v=wZfVBwOO0-k"},{"text":"Visual Perception with Deep Learning","link":"https://www.youtube.com/watch?v=3boKlkPBckA"},{"text":"The Next Generation of Neural Networks","link":"https://www.youtube.com/watch?v=AyzOUbkUf3M"},{"text":"The wonderful and terrifying implications of computers that can learn","link":"http://www.ted.com/talks/jeremy_howard_the_wonderful_and_terrifying_implications_of_computers_that_can_learn"},{"text":"Unsupervised Deep Learning - Stanford","link":"http://web.stanford.edu/class/cs294a/handouts.html"},{"text":"Natural Language Processing","link":"http://web.stanford.edu/class/cs224n/handouts/"},{"text":"A beginners Guide to Deep Neural Networks","link":"http://googleresearch.blogspot.com/2015/09/a-beginners-guide-to-deep-neural.html"},{"text":"Deep Learning: Intelligence from Big Data","link":"https://www.youtube.com/watch?v=czLI3oLDe8M"},{"text":"Introduction to Artificial Neural Networks and Deep Learning","link":"https://www.youtube.com/watch?v=FoO8qDB8gUU"}]},{"text":"Videos and Lectures","link":"#videos-and-lectures","contents":[]},{"text":"Papers","link":"#papers","contents":[{"text":"ImageNet Classification with Deep Convolutional Neural Networks","link":"http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf"},{"text":"Using Very Deep Autoencoders for Content Based Image Retrieval","link":"http://www.cs.toronto.edu/~hinton/absps/esann-deep-final.pdf"},{"text":"Learning Deep Architectures for AI","link":"http://www.iro.umontreal.ca/~lisa/pointeurs/TR1312.pdf"},{"text":"CMUâ€™s list of papers","link":"http://deeplearning.cs.cmu.edu/"},{"text":"Neural Networks for Named Entity\nRecognition","link":"http://nlp.stanford.edu/~socherr/pa4_ner.pdf"},{"text":"Training tricks by YB","link":"http://www.iro.umontreal.ca/~bengioy/papers/YB-tricks.pdf"},{"text":"http://www.cs.toronto.edu/~hinton/deeprefs.html","link":"http://www.cs.toronto.edu/~hinton/deeprefs.html"},{"text":"Supervised Sequence Labelling with Recurrent Neural Networks","link":"http://www.cs.toronto.edu/~graves/preprint.pdf"},{"text":"Statistical Language Models based on Neural Networks","link":"http://www.fit.vutbr.cz/~imikolov/rnnlm/thesis.pdf"},{"text":"Training Recurrent Neural Networks","link":"http://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf"},{"text":"Recursive Deep Learning for Natural Language Processing and Computer Vision","link":"http://nlp.stanford.edu/~socherr/thesis.pdf"},{"text":"Bi-directional RNN","link":"http://www.di.ufpe.br/~fnj/RNA/bibliografia/BRNN.pdf"},{"text":"LSTM","link":"http://web.eecs.utk.edu/~itamar/courses/ECE-692/Bobby_paper1.pdf"},{"text":"GRU - Gated Recurrent Unit","link":"http://arxiv.org/pdf/1406.1078v3.pdf"},{"text":"GFRNN","link":"http://arxiv.org/pdf/1502.02367v3.pdf"},{"text":"LSTM: A Search Space Odyssey","link":"http://arxiv.org/pdf/1503.04069v1.pdf"},{"text":"A Critical Review of Recurrent Neural Networks for Sequence Learning","link":"http://arxiv.org/pdf/1506.00019v1.pdf"},{"text":"Visualizing and Understanding Recurrent Networks","link":"http://arxiv.org/pdf/1506.02078v1.pdf"},{"text":"Wojciech Zaremba, Ilya Sutskever, An Empirical Exploration of Recurrent Network Architectures","link":"http://jmlr.org/proceedings/papers/v37/jozefowicz15.pdf"},{"text":"Recurrent Neural Network based Language Model","link":"http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf"},{"text":"Extensions of Recurrent Neural Network Language Model","link":"http://www.fit.vutbr.cz/research/groups/speech/publi/2011/mikolov_icassp2011_5528.pdf"},{"text":"Recurrent Neural Network based Language Modeling in Meeting Recognition","link":"http://www.fit.vutbr.cz/~imikolov/rnnlm/ApplicationOfRNNinMeetingRecognition_IS2011.pdf"},{"text":"Deep Neural Networks for Acoustic Modeling in Speech Recognition","link":"http://cs224d.stanford.edu/papers/maas_paper.pdf"},{"text":"Speech Recognition with Deep Recurrent Neural Networks","link":"http://www.cs.toronto.edu/~fritz/absps/RNN13.pdf"},{"text":"Reinforcement Learning Neural Turing Machines","link":"http://arxiv.org/pdf/1505.00521v1"},{"text":"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation","link":"http://arxiv.org/pdf/1406.1078v3.pdf"},{"text":"Google - Sequence to Sequence  Learning with Nneural Networks","link":"http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf"},{"text":"Memory Networks","link":"http://arxiv.org/pdf/1410.3916v10"},{"text":"Policy Learning with Continuous Memory States for Partially Observed Robotic Control","link":"http://arxiv.org/pdf/1507.01273v1"},{"text":"Microsoft - Jointly Modeling Embedding and Translation to Bridge Video and Language","link":"http://arxiv.org/pdf/1505.01861v1.pdf"},{"text":"Neural Turing Machines","link":"http://arxiv.org/pdf/1410.5401v2.pdf"},{"text":"Ask Me Anything: Dynamic Memory Networks for Natural Language Processing","link":"http://arxiv.org/pdf/1506.07285v1.pdf"},{"text":"Mastering the Game of Go with Deep Neural Networks and Tree Search","link":"http://www.nature.com/nature/journal/v529/n7587/pdf/nature16961.pdf"},{"text":"Batch Normalization","link":"https://arxiv.org/abs/1502.03167"},{"text":"Residual Learning","link":"https://arxiv.org/pdf/1512.03385v1.pdf"}]},{"text":"Tutorials","link":"#tutorials","contents":[{"text":"UFLDL Tutorial 1","link":"http://deeplearning.stanford.edu/wiki/index.php/UFLDL_Tutorial"},{"text":"UFLDL Tutorial 2","link":"http://ufldl.stanford.edu/tutorial/supervised/LinearRegression/"},{"text":"Deep Learning for NLP (without Magic)","link":"http://www.socher.org/index.php/DeepLearningTutorial/DeepLearningTutorial"},{"text":"A Deep Learning Tutorial: From Perceptrons to Deep Networks","link":"http://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks"},{"text":"Deep Learning from the Bottom up","link":"http://www.metacademy.org/roadmaps/rgrosse/deep_learning"},{"text":"Theano Tutorial","link":"http://deeplearning.net/tutorial/deeplearning.pdf"},{"text":"Neural Networks for Matlab","link":"http://uk.mathworks.com/help/pdf_doc/nnet/nnet_ug.pdf"},{"text":"Using convolutional neural nets to detect facial keypoints tutorial","link":"http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/"},{"text":"Torch7 Tutorials","link":"http://code.madbits.com/wiki/doku.php"},{"text":"https://github.com/josephmisiti/machine-learning-module","link":"https://github.com/josephmisiti/machine-learning-module"},{"text":"VGG Convolutional Neural Networks Practical","link":"http://www.robots.ox.ac.uk/~vgg/practicals/cnn/index.html"},{"text":"TensorFlow tutorials","link":"https://github.com/nlintz/TensorFlow-Tutorials"},{"text":"More TensorFlow tutorials","link":"https://github.com/pkmital/tensorflow_tutorials"},{"text":"TensorFlow Python Notebooks","link":"https://github.com/aymericdamien/TensorFlow-Examples"},{"text":"Keras and Lasagne Deep Learning Tutorials","link":"https://github.com/Vict0rSch/deep_learning"}]},{"text":"Researchers","link":"#researchers","contents":[{"text":"Aaron Courville","link":"http://aaroncourville.wordpress.com"},{"text":"Abdel-rahman Mohamed","link":"http://www.cs.toronto.edu/~asamir/"},{"text":"Adam Coates","link":"http://cs.stanford.edu/~acoates/"},{"text":"Alex Acero","link":"http://research.microsoft.com/en-us/people/alexac/"},{"text":" Alex Krizhevsky ","link":"http://www.cs.utoronto.ca/~kriz/index.html"},{"text":" Alexander Ilin ","link":"http://users.ics.aalto.fi/alexilin/"},{"text":" Amos Storkey ","link":"http://homepages.inf.ed.ac.uk/amos/"},{"text":" Andrej Karpathy ","link":"http://cs.stanford.edu/~karpathy/"},{"text":" Andrew M. Saxe ","link":"http://www.stanford.edu/~asaxe/"},{"text":" Andrew Ng ","link":"http://www.cs.stanford.edu/people/ang/"},{"text":" Andrew W. Senior ","link":"http://research.google.com/pubs/author37792.html"},{"text":" Andriy Mnih ","link":"http://www.gatsby.ucl.ac.uk/~amnih/"},{"text":" Ayse Naz Erkan ","link":"http://www.cs.nyu.edu/~naz/"},{"text":" Benjamin Schrauwen ","link":"http://reslab.elis.ugent.be/benjamin"},{"text":" Bernardete Ribeiro ","link":"https://www.cisuc.uc.pt/people/show/2020"},{"text":" Bo David Chen ","link":"http://vision.caltech.edu/~bchen3/Site/Bo_David_Chen.html"},{"text":" Boureau Y-Lan ","link":"http://cs.nyu.edu/~ylan/"},{"text":" Brian Kingsbury ","link":"http://researcher.watson.ibm.com/researcher/view.php?person=us-bedk"},{"text":" Christopher Manning ","link":"http://nlp.stanford.edu/~manning/"},{"text":" Clement Farabet ","link":"http://www.clement.farabet.net/"},{"text":" Dan Claudiu CireÈ™an ","link":"http://www.idsia.ch/~ciresan/"},{"text":" David Reichert ","link":"http://serre-lab.clps.brown.edu/person/david-reichert/"},{"text":" Derek Rose ","link":"http://mil.engr.utk.edu/nmil/member/5"},{"text":" Dong Yu ","link":"http://research.microsoft.com/en-us/people/dongyu/default.aspx"},{"text":" Drausin Wulsin ","link":"http://www.seas.upenn.edu/~wulsin/"},{"text":" Erik M. Schmidt ","link":"http://music.ece.drexel.edu/people/eschmidt"},{"text":" Eugenio Culurciello ","link":"https://engineering.purdue.edu/BME/People/viewPersonById?resource_id=71333"},{"text":" Frank Seide ","link":"http://research.microsoft.com/en-us/people/fseide/"},{"text":" Galen Andrew ","link":"http://homes.cs.washington.edu/~galen/"},{"text":" Geoffrey Hinton ","link":"http://www.cs.toronto.edu/~hinton/"},{"text":" George Dahl ","link":"http://www.cs.toronto.edu/~gdahl/"},{"text":" Graham Taylor ","link":"http://www.uoguelph.ca/~gwtaylor/"},{"text":" GrÃ©goire Montavon ","link":"http://gregoire.montavon.name/"},{"text":" Guido Francisco MontÃºfar ","link":"http://personal-homepages.mis.mpg.de/montufar/"},{"text":" Guillaume Desjardins ","link":"http://brainlogging.wordpress.com/"},{"text":" Hannes Schulz ","link":"http://www.ais.uni-bonn.de/~schulz/"},{"text":" HÃ©lÃ¨ne Paugam-Moisy ","link":"http://www.lri.fr/~hpaugam/"},{"text":" Honglak Lee ","link":"http://web.eecs.umich.edu/~honglak/"},{"text":" Hugo Larochelle ","link":"http://www.dmi.usherb.ca/~larocheh/index_en.html"},{"text":" Ilya Sutskever ","link":"http://www.cs.toronto.edu/~ilya/"},{"text":" Itamar Arel ","link":"http://mil.engr.utk.edu/nmil/member/2"},{"text":" James Martens ","link":"http://www.cs.toronto.edu/~jmartens/"},{"text":" Jason Morton ","link":"http://www.jasonmorton.com/"},{"text":" Jason Weston ","link":"http://www.thespermwhale.com/jaseweston/"},{"text":" Jeff Dean ","link":"http://research.google.com/pubs/jeff.html"},{"text":" Jiquan Mgiam ","link":"http://cs.stanford.edu/~jngiam/"},{"text":" Joseph Turian ","link":"http://www-etud.iro.umontreal.ca/~turian/"},{"text":" Joshua Matthew Susskind ","link":"http://aclab.ca/users/josh/index.html"},{"text":" JÃ¼rgen Schmidhuber ","link":"http://www.idsia.ch/~juergen/"},{"text":" Justin A. Blanco ","link":"https://sites.google.com/site/blancousna/"},{"text":" Koray Kavukcuoglu ","link":"http://koray.kavukcuoglu.org/"},{"text":" KyungHyun Cho ","link":"http://users.ics.aalto.fi/kcho/"},{"text":" Li Deng ","link":"http://research.microsoft.com/en-us/people/deng/"},{"text":" Lucas Theis ","link":"http://www.kyb.tuebingen.mpg.de/nc/employee/details/lucas.html"},{"text":" Ludovic Arnold ","link":"http://ludovicarnold.altervista.org/home/"},{"text":" Marc'Aurelio Ranzato ","link":"http://www.cs.nyu.edu/~ranzato/"},{"text":" Martin LÃ¤ngkvist ","link":"http://aass.oru.se/~mlt/"},{"text":" Misha Denil ","link":"http://www.cs.ubc.ca/~mdenil/"},{"text":" Mohammad Norouzi ","link":"http://www.cs.toronto.edu/~norouzi/"},{"text":" Nando de Freitas ","link":"http://www.cs.ubc.ca/~nando/"},{"text":" Navdeep Jaitly ","link":"http://www.cs.utoronto.ca/~ndjaitly/"},{"text":" Nicolas Le Roux ","link":"http://nicolas.le-roux.name/"},{"text":" Nitish Srivastava ","link":"http://www.cs.toronto.edu/~nitish/"},{"text":" Noel Lopes ","link":"https://www.cisuc.uc.pt/people/show/2028"},{"text":" Oriol Vinyals ","link":"http://www.cs.berkeley.edu/~vinyals/"},{"text":" Pascal Vincent ","link":"http://www.iro.umontreal.ca/~vincentp"},{"text":" Patrick Nguyen ","link":"https://sites.google.com/site/drpngx/"},{"text":" Pedro Domingos ","link":"http://homes.cs.washington.edu/~pedrod/"},{"text":" Peggy Series ","link":"http://homepages.inf.ed.ac.uk/pseries/"},{"text":" Pierre Sermanet ","link":"http://cs.nyu.edu/~sermanet"},{"text":" Piotr Mirowski ","link":"http://www.cs.nyu.edu/~mirowski/"},{"text":" Quoc V. Le ","link":"http://ai.stanford.edu/~quocle/"},{"text":" Reinhold Scherer ","link":"http://bci.tugraz.at/scherer/"},{"text":" Richard Socher ","link":"http://www.socher.org/"},{"text":" Rob Fergus ","link":"http://cs.nyu.edu/~fergus/pmwiki/pmwiki.php"},{"text":" Robert Coop ","link":"http://mil.engr.utk.edu/nmil/member/19"},{"text":" Robert Gens ","link":"http://homes.cs.washington.edu/~rcg/"},{"text":" Roger Grosse ","link":"http://people.csail.mit.edu/rgrosse/"},{"text":" Ronan Collobert ","link":"http://ronan.collobert.com/"},{"text":" Ruslan Salakhutdinov ","link":"http://www.utstat.toronto.edu/~rsalakhu/"},{"text":" Sebastian Gerwinn ","link":"http://www.kyb.tuebingen.mpg.de/nc/employee/details/sgerwinn.html"},{"text":" StÃ©phane Mallat ","link":"http://www.cmap.polytechnique.fr/~mallat/"},{"text":" Sven Behnke ","link":"http://www.ais.uni-bonn.de/behnke/"},{"text":" Tapani Raiko ","link":"http://users.ics.aalto.fi/praiko/"},{"text":" Tara Sainath ","link":"https://sites.google.com/site/tsainath/"},{"text":" Tijmen Tieleman ","link":"http://www.cs.toronto.edu/~tijmen/"},{"text":" Tom Karnowski ","link":"http://mil.engr.utk.edu/nmil/member/36"},{"text":" TomÃ¡Å¡ Mikolov ","link":"https://research.facebook.com/tomas-mikolov"},{"text":" Ueli Meier ","link":"http://www.idsia.ch/~meier/"},{"text":" Vincent Vanhoucke ","link":"http://vincent.vanhoucke.com"},{"text":" Volodymyr Mnih ","link":"http://www.cs.toronto.edu/~vmnih/"},{"text":" Yann LeCun ","link":"http://yann.lecun.com/"},{"text":" Yichuan Tang ","link":"http://www.cs.toronto.edu/~tang/"},{"text":" Yoshua Bengio ","link":"http://www.iro.umontreal.ca/~bengioy/yoshua_en/index.html"},{"text":" Yotaro Kubo ","link":"http://yota.ro/"},{"text":" Youzhi (Will) Zou","link":"http://ai.stanford.edu/~wzou"}]},{"text":"WebSites","link":"#websites","contents":[{"text":"deeplearning.net","link":"http://deeplearning.net/"},{"text":"deeplearning.stanford.edu","link":"http://deeplearning.stanford.edu/"},{"text":"nlp.stanford.edu","link":"http://nlp.stanford.edu/"},{"text":"ai-junkie.com","link":"http://www.ai-junkie.com/ann/evolved/nnt1.html"},{"text":"cs.brown.edu/research/ai","link":"http://cs.brown.edu/research/ai/"},{"text":"eecs.umich.edu/ai","link":"http://www.eecs.umich.edu/ai/"},{"text":"cs.utexas.edu/users/ai-lab","link":"http://www.cs.utexas.edu/users/ai-lab/"},{"text":"cs.washington.edu/research/ai","link":"http://www.cs.washington.edu/research/ai/"},{"text":"aiai.ed.ac.uk","link":"http://www.aiai.ed.ac.uk/"},{"text":"www-aig.jpl.nasa.gov","link":"http://www-aig.jpl.nasa.gov/"},{"text":"csail.mit.edu","link":"http://www.csail.mit.edu/"},{"text":"cgi.cse.unsw.edu.au/~aishare","link":"http://cgi.cse.unsw.edu.au/~aishare/"},{"text":"cs.rochester.edu/research/ai","link":"http://www.cs.rochester.edu/research/ai/"},{"text":"ai.sri.com","link":"http://www.ai.sri.com/"},{"text":"isi.edu/AI/isd.htm","link":"http://www.isi.edu/AI/isd.htm"},{"text":"nrl.navy.mil/itd/aic","link":"http://www.nrl.navy.mil/itd/aic/"},{"text":"hips.seas.harvard.edu","link":"http://hips.seas.harvard.edu/"},{"text":"AI Weekly","link":"http://aiweekly.co"},{"text":"stat.ucla.edu","link":"http://www.stat.ucla.edu/~junhua.mao/m-RNN.html"},{"text":"deeplearning.cs.toronto.edu","link":"http://deeplearning.cs.toronto.edu/i2t"},{"text":"jeffdonahue.com/lrcn/","link":"http://jeffdonahue.com/lrcn/"},{"text":"visualqa.org","link":"http://www.visualqa.org/"},{"text":"www.mpi-inf.mpg.de/departments/computer-vision...","link":"https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/"},{"text":"Deep Learning News","link":"http://news.startup.ml/"}]},{"text":"Datasets","link":"#datasets","contents":[{"text":"MNIST","link":"http://yann.lecun.com/exdb/mnist/"},{"text":"Google House Numbers","link":"http://ufldl.stanford.edu/housenumbers/"},{"text":"CIFAR-10 and CIFAR-100","link":"http://www.cs.toronto.edu/~kriz/cifar.html"},{"text":"IMAGENET","link":"http://www.image-net.org/"},{"text":"Tiny Images","link":"http://groups.csail.mit.edu/vision/TinyImages/"},{"text":"Flickr Data","link":"http://yahoolabs.tumblr.com/post/89783581601/one-hundred-million-creative-commons-flickr-images"},{"text":"Berkeley Segmentation Dataset 500","link":"http://www.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/"},{"text":"UC Irvine Machine Learning Repository","link":"http://archive.ics.uci.edu/ml/"},{"text":"Flickr 8k","link":"http://nlp.cs.illinois.edu/HockenmaierGroup/Framing_Image_Description/KCCA.html"},{"text":"Flickr 30k","link":"http://shannon.cs.illinois.edu/DenotationGraph/"},{"text":"Microsoft COCO","link":"http://mscoco.org/home/"},{"text":"VQA","link":"http://www.visualqa.org/"},{"text":"Image QA","link":"http://www.cs.toronto.edu/~mren/imageqa/data/cocoqa/"},{"text":"AT&T Laboratories Cambridge face database","link":"http://www.uk.research.att.com/facedatabase.html"},{"text":"AVHRR Pathfinder","link":"http://xtreme.gsfc.nasa.gov"},{"text":"Air Freight","link":"http://www.anc.ed.ac.uk/~amos/afreightdata.html"},{"text":"Amsterdam Library of Object Images","link":"http://www.science.uva.nl/~aloi/"},{"text":"Annotated face, hand, cardiac & meat images","link":"http://www.imm.dtu.dk/~aam/"},{"text":"Image Analysis and Computer Graphics","link":"http://www.imm.dtu.dk/image/"},{"text":"Brown University Stimuli","link":"http://www.cog.brown.edu/~tarr/stimuli.html"},{"text":"CAVIAR video sequences of mall and public space behavior","link":"http://homepages.inf.ed.ac.uk/rbf/CAVIARDATA1/"},{"text":"Machine Vision Unit","link":"http://www.ipab.inf.ed.ac.uk/mvu/"},{"text":"CCITT Fax standard images","link":"http://www.cs.waikato.ac.nz/~singlis/ccitt.html"},{"text":"CMU CIL's Stereo Data with Ground Truth","link":"cil-ster.html"},{"text":"CMU PIE Database","link":"http://www.ri.cmu.edu/projects/project_418.html"},{"text":"CMU VASC Image Database","link":"http://www.ius.cs.cmu.edu/idb/"},{"text":"Caltech Image Database","link":"http://www.vision.caltech.edu/html-files/archive.html"},{"text":"Columbia-Utrecht Reflectance and Texture Database","link":"http://www.cs.columbia.edu/CAVE/curet/"},{"text":"Computational Colour Constancy Data","link":"http://www.cs.sfu.ca/~colour/data/index.html"},{"text":"Computational Vision Lab","link":"http://www.cs.sfu.ca/~colour/"},{"text":"Content-based image retrieval database","link":"http://www.cs.washington.edu/research/imagedatabase/groundtruth/"},{"text":"Efficient Content-based Retrieval Group","link":"http://www.cs.washington.edu/research/imagedatabase/"},{"text":"Densely Sampled View Spheres","link":"http://ls7-www.cs.uni-dortmund.de/~peters/pages/research/modeladaptsys/modeladaptsys_vba_rov.html"},{"text":"Computer Science VII (Graphical Systems)","link":"http://ls7-www.cs.uni-dortmund.de/"},{"text":"Digital Embryos","link":"http://vision.psych.umn.edu/www/kersten-lab/demos/digitalembryo.html"},{"text":"Univerity of Minnesota Vision Lab","link":"http://vision.psych.umn.edu/www/kersten-lab/kersten-lab.html"},{"text":"El Salvador Atlas of Gastrointestinal VideoEndoscopy","link":"http://www.gastrointestinalatlas.com"},{"text":"FG-NET Facial Aging Database","link":"http://sting.cycollege.ac.cy/~alanitis/fgnetaging/index.htm"},{"text":"FVC2000 Fingerprint Databases","link":"http://bias.csr.unibo.it/fvc2000/"},{"text":"Biometric Systems Lab","link":"http://bias.csr.unibo.it/research/biolab"},{"text":"Face and Gesture images and image sequences","link":"http://www.fg-net.org"},{"text":"German Fingerspelling Database","link":"http://www-i6.informatik.rwth-aachen.de/~dreuw/database.html"},{"text":"Language Processing and Pattern Recognition","link":"http://www-i6.informatik.rwth-aachen.de/"},{"text":"Groningen Natural Image Database","link":"http://hlab.phys.rug.nl/archive.html"},{"text":"ICG Testhouse sequence","link":"http://www.icg.tu-graz.ac.at/~schindler/Data"},{"text":"Institute of Computer Graphics and Vision","link":"http://www.icg.tu-graz.ac.at"},{"text":"IEN Image Library","link":"http://www.ien.it/is/vislib/"},{"text":"INRIA's Syntim images database","link":"http://www-rocq.inria.fr/~tarel/syntim/images.html"},{"text":"INRIA","link":"http://www.inria.fr/"},{"text":"INRIA's Syntim stereo databases","link":"http://www-rocq.inria.fr/~tarel/syntim/paires.html"},{"text":"Image Analysis Laboratory","link":"http://www.ece.ncsu.edu/imaging/Archives/ImageDataBase/index.html"},{"text":"Image Analysis Laboratory","link":"http://www.ece.ncsu.edu/imaging"},{"text":"Image Database","link":"http://www.prip.tuwien.ac.at/prip/image.html"},{"text":"JAFFE Facial Expression Image Database","link":"http://www.mis.atr.co.jp/~mlyons/jaffe.html"},{"text":"ATR Research, Kyoto, Japan","link":"http://www.mic.atr.co.jp/"},{"text":"JISCT Stereo Evaluation","link":"ftp://ftp.vislist.com/IMAGERY/JISCT/"},{"text":"MIT Vision Texture","link":"http://www-white.media.mit.edu/vismod/imagery/VisionTexture/vistex.html"},{"text":"MIT face images and more","link":"ftp://whitechapel.media.mit.edu/pub/images"},{"text":"Machine Vision","link":"http://vision.cse.psu.edu/book/testbed/images/"},{"text":"Mammography Image Databases","link":"http://marathon.csee.usf.edu/Mammography/Database.html"},{"text":"ftp://ftp.cps.msu.edu/pub/prip","link":"ftp://ftp.cps.msu.edu/pub/prip"},{"text":"Middlebury Stereo Data Sets with Ground Truth","link":"http://www.middlebury.edu/stereo/data.html"},{"text":"Middlebury Stereo Vision Research Page","link":"http://www.middlebury.edu/stereo"},{"text":"Modis Airborne simulator, Gallery and data set","link":"http://ltpwww.gsfc.nasa.gov/MODIS/MAS/"},{"text":"NIST Fingerprint and handwriting","link":"ftp://sequoyah.ncsl.nist.gov/pub/databases/data"},{"text":"NIST Fingerprint data","link":"ftp://ftp.cs.columbia.edu/jpeg/other/uuencoded"},{"text":"NLM HyperDoc Visible Human Project","link":"http://www.nlm.nih.gov/research/visible/visible_human.html"},{"text":"National Design Repository","link":"http://www.designrepository.org"},{"text":"Geometric & Intelligent Computing Laboratory","link":"http://gicl.mcs.drexel.edu"},{"text":"OSU (MSU) 3D Object Model Database","link":"http://eewww.eng.ohio-state.edu/~flynn/3DDB/Models/"},{"text":"OSU (MSU/WSU) Range Image Database","link":"http://eewww.eng.ohio-state.edu/~flynn/3DDB/RID/"},{"text":"OSU/SAMPL Database: Range Images, 3D Models, Stills, Motion Sequences","link":"http://sampl.eng.ohio-state.edu/~sampl/database.htm"},{"text":"Signal Analysis and Machine Perception Laboratory","link":"http://sampl.eng.ohio-state.edu"},{"text":"Otago Optical Flow Evaluation Sequences","link":"http://www.cs.otago.ac.nz/research/vision/Research/OpticalFlow/opticalflow.html"},{"text":"Vision Research Group","link":"http://www.cs.otago.ac.nz/research/vision/index.html"},{"text":"ftp://ftp.limsi.fr/pub/quenot/opflow/testdata/piv/","link":"ftp://ftp.limsi.fr/pub/quenot/opflow/testdata/piv/"},{"text":"LIMSI-CNRS/CHM/IMM/vision","link":"http://www.limsi.fr/Recherche/IMM/PageIMM.html"},{"text":"LIMSI-CNRS","link":"http://www.limsi.fr/"},{"text":"Photometric 3D Surface Texture Database","link":"http://www.taurusstudio.net/research/pmtexdb/index.htm"},{"text":"SEQUENCES FOR OPTICAL FLOW ANALYSIS (SOFA)","link":"http://www.cee.hw.ac.uk/~mtc/sofa"},{"text":"Computer Vision Group","link":"http://www.cee.hw.ac.uk/~mtc/research.html"},{"text":"Sequences for Flow Based Reconstruction","link":"http://www.nada.kth.se/~zucch/CAMERA/PUB/seq.html"},{"text":"Stereo Images with Ground Truth Disparity and Occlusion","link":"http://www-dbv.cs.uni-bonn.de/stereo_data/"},{"text":"Stuttgart Range Image Database","link":"http://range.informatik.uni-stuttgart.de"},{"text":"Department Image Understanding","link":"http://www.informatik.uni-stuttgart.de/ipvr/bv/bv_home_engl.html"},{"text":"The AR Face Database","link":"http://rvl1.ecn.purdue.edu/~aleix/aleix_face_DB.html"},{"text":"Purdue Robot Vision Lab","link":"http://rvl.www.ecn.purdue.edu/RVL/"},{"text":"The MIT-CSAIL Database of Objects and Scenes","link":"http://web.mit.edu/torralba/www/database.html"},{"text":"The RVL SPEC-DB (SPECularity DataBase)","link":"http://rvl1.ecn.purdue.edu/RVL/specularity_database/"},{"text":"Robot Vision Laboratory","link":"http://rvl1.ecn.purdue.edu/RVL/"},{"text":"The Xm2vts database","link":"http://xm2vtsdb.ee.surrey.ac.uk"},{"text":"Centre for Vision, Speech and Signal Processing","link":"http://www.ee.surrey.ac.uk/Research/CVSSP"},{"text":"Traffic Image Sequences and 'Marbled Block' Sequence","link":"http://i21www.ira.uka.de/image_sequences"},{"text":"IAKS/KOGS","link":"http://i21www.ira.uka.de"},{"text":"U Bern Face images","link":"ftp://ftp.iam.unibe.ch/pub/Images/FaceImages"},{"text":"U Michigan textures","link":"ftp://freebie.engin.umich.edu/pub/misc/textures"},{"text":"U Oulu wood and knots database","link":"http://www.ee.oulu.fi/~olli/Projects/Lumber.Grading.html"},{"text":"UCID - an Uncompressed Colour Image Database","link":"http://vision.doc.ntu.ac.uk/datasets/UCID/ucid.html"},{"text":"UMass Vision Image Archive","link":"http://vis-www.cs.umass.edu/~vislib/"},{"text":"UNC's 3D image database","link":"ftp://sunsite.unc.edu/pub/academic/computer-science/virtual-reality/3d"},{"text":"USF Range Image Data with Segmentation Ground Truth","link":"http://marathon.csee.usf.edu/range/seg-comp/SegComp.html"},{"text":"University of Oulu Physics-based Face Database","link":"http://www.ee.oulu.fi/research/imag/color/pbfd.html"},{"text":"Machine Vision and Media Processing Unit","link":"http://www.ee.oulu.fi/mvmp/"},{"text":"University of Oulu Texture Database","link":"http://www.outex.oulu.fi"},{"text":"Machine Vision Group","link":"http://www.ee.oulu.fi/mvg"},{"text":"Usenix face database","link":"ftp://ftp.uu.net/published/usenix/faces"},{"text":"View Sphere Database","link":"http://www-prima.inrialpes.fr/Prima/hall/view_sphere.html"},{"text":"PRIMA, GRAVIR","link":"http://www-prima.inrialpes.fr/Prima/"},{"text":"Vision-list Imagery Archive","link":"ftp://ftp.vislist.com/IMAGERY/"},{"text":"Wiry Object Recognition Database","link":"http://www.cs.cmu.edu/~owenc/word.htm"},{"text":"3D Vision Group","link":"http://www.cs.cmu.edu/0.000000E+003dvision/"},{"text":"Yale Face Database","link":"http://cvc.yale.edu/projects/yalefaces/yalefaces.html"},{"text":"Yale Face Database B","link":"http://cvc.yale.edu/projects/yalefacesB/yalefacesB.html"},{"text":"Center for Computational Vision and Control","link":"http://cvc.yale.edu/"},{"text":"DeepMind QA Corpus","link":"https://github.com/deepmind/rc-data"}]},{"text":"Frameworks","link":"#frameworks","contents":[{"text":"Caffe","link":"http://caffe.berkeleyvision.org/"},{"text":"Torch7","link":"http://torch.ch/"},{"text":"Theano","link":"http://deeplearning.net/software/theano/"},{"text":"cuda-convnet","link":"https://code.google.com/p/cuda-convnet2/"},{"text":"convetjs","link":"https://github.com/karpathy/convnetjs"},{"text":"Ccv","link":"http://libccv.org/doc/doc-convnet/"},{"text":"NuPIC","link":"http://numenta.org/nupic.html"},{"text":"DeepLearning4J","link":"http://deeplearning4j.org/"},{"text":"Brain","link":"https://github.com/harthur/brain"},{"text":"DeepLearnToolbox","link":"https://github.com/rasmusbergpalm/DeepLearnToolbox"},{"text":"Deepnet","link":"https://github.com/nitishsrivastava/deepnet"},{"text":"Deeppy","link":"https://github.com/andersbll/deeppy"},{"text":"JavaNN","link":"https://github.com/ivan-vasilev/neuralnetworks"},{"text":"hebel","link":"https://github.com/hannes-brt/hebel"},{"text":"Mocha.jl","link":"https://github.com/pluskid/Mocha.jl"},{"text":"OpenDL","link":"https://github.com/guoding83128/OpenDL"},{"text":"cuDNN","link":"https://developer.nvidia.com/cuDNN"},{"text":"MGL","link":"http://melisgl.github.io/mgl-pax-world/mgl-manual.html"},{"text":"Knet.jl","link":"https://github.com/denizyuret/Knet.jl"},{"text":"Nvidia DIGITS - a web app based on Caffe","link":"https://github.com/NVIDIA/DIGITS"},{"text":"Neon - Python based Deep Learning Framework","link":"https://github.com/NervanaSystems/neon"},{"text":"Keras - Theano based Deep Learning Library","link":"http://keras.io"},{"text":"Chainer - A flexible framework of neural networks for deep learning","link":"http://chainer.org/"},{"text":"RNNLM Toolkit","link":"http://rnnlm.org/"},{"text":"RNNLIB - A recurrent neural network library","link":"http://sourceforge.net/p/rnnl/wiki/Home/"},{"text":"char-rnn","link":"https://github.com/karpathy/char-rnn"},{"text":"MatConvNet: CNNs for MATLAB","link":"https://github.com/vlfeat/matconvnet"},{"text":"Minerva - a fast and flexible tool for deep learning on multi-GPU","link":"https://github.com/dmlc/minerva"},{"text":"Brainstorm - Fast, flexible and fun neural networks.","link":"https://github.com/IDSIA/brainstorm"},{"text":"Tensorflow - Open source software library for numerical computation using data flow graphs","link":"https://github.com/tensorflow/tensorflow"},{"text":"DMTK - Microsoft Distributed Machine Learning Tookit","link":"https://github.com/Microsoft/DMTK"},{"text":"Scikit Flow - Simplified interface for TensorFlow (mimicking Scikit Learn)","link":"https://github.com/google/skflow"},{"text":"MXnet - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning framework","link":"https://github.com/dmlc/mxnet/"},{"text":"Veles - Samsung Distributed machine learning platform","link":"https://github.com/Samsung/veles"},{"text":"Marvin - A Minimalist GPU-only N-Dimensional ConvNets Framework","link":"https://github.com/PrincetonVision/marvin"},{"text":"Apache SINGA - A General Distributed Deep Learning Platform","link":"http://singa.incubator.apache.org/"},{"text":"DSSTNE - Amazon's library for building Deep Learning models","link":"https://github.com/amznlabs/amazon-dsstne"},{"text":"SyntaxNet - Google's syntactic parser - A TensorFlow dependency library","link":"https://github.com/tensorflow/models/tree/master/syntaxnet"},{"text":"mlpack - A scalable Machine Learning library","link":"http://mlpack.org/"},{"text":"Torchnet - Torch based Deep Learning Library","link":"https://github.com/torchnet/torchnet"},{"text":"Paddle - PArallel Distributed Deep LEarning by Baidu","link":"https://github.com/baidu/paddle"}]},{"text":"Miscellaneous","link":"#miscellaneous","contents":[{"text":"Google Plus - Deep Learning Community","link":"https://plus.google.com/communities/112866381580457264725"},{"text":"Caffe Webinar","link":"http://on-demand-gtc.gputechconf.com/gtcnew/on-demand-gtc.php?searchByKeyword=shelhamer&searchItems=&sessionTopic=&sessionEvent=4&sessionYear=2014&sessionFormat=&submit=&select=+"},{"text":"100 Best Github Resources in Github for DL","link":"http://meta-guide.com/software-meta-guide/100-best-github-deep-learning/"},{"text":"Word2Vec","link":"https://code.google.com/p/word2vec/"},{"text":"Caffe DockerFile","link":"https://github.com/tleyden/docker/tree/master/caffe"},{"text":"TorontoDeepLEarning convnet","link":"https://github.com/TorontoDeepLearning/convnet"},{"text":"gfx.js","link":"https://github.com/clementfarabet/gfx.js"},{"text":"Torch7 Cheat sheet","link":"https://github.com/torch/torch7/wiki/Cheatsheet"},{"text":"http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-864-advanced-natural-language-processing-fall-2005/","link":"http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-864-advanced-natural-language-processing-fall-2005/"},{"text":"Misc from MIT's 'Machine Learning' course","link":"http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-867-machine-learning-fall-2006/lecture-notes/"},{"text":"Misc from MIT's 'Networks for Learning: Regression and Classification' course","link":"http://ocw.mit.edu/courses/brain-and-cognitive-sciences/9-520-a-networks-for-learning-regression-and-classification-spring-2001/"},{"text":"Misc from MIT's 'Neural Coding and Perception of Sound' course","link":"http://ocw.mit.edu/courses/health-sciences-and-technology/hst-723j-neural-coding-and-perception-of-sound-spring-2005/index.htm"},{"text":"Implementing a Distributed Deep Learning Network over Spark","link":"http://www.datasciencecentral.com/profiles/blogs/implementing-a-distributed-deep-learning-network-over-spark"},{"text":"A chess AI that learns to play chess using deep learning.","link":"https://github.com/erikbern/deep-pink"},{"text":"https://github.com/kristjankorjus/Replicating-DeepMind","link":"https://github.com/kristjankorjus/Replicating-DeepMind"},{"text":"Wiki2Vec. Getting Word2vec vectors for entities and word from Wikipedia Dumps","link":"https://github.com/idio/wiki2vec"},{"text":"The original code from the DeepMind article + tweaks","link":"https://github.com/kuz/DeepMind-Atari-Deep-Q-Learner"},{"text":"Google deepdream - Neural Network art","link":"https://github.com/google/deepdream"},{"text":"An efficient, batched LSTM.","link":"https://gist.github.com/karpathy/587454dc0146a6ae21fc"},{"text":"A recurrent neural network designed to generate classical music.","link":"https://github.com/hexahedria/biaxial-rnn-music-composition"},{"text":"Memory Networks Implementations - Facebook","link":"https://github.com/facebook/MemNN"},{"text":"Face recognition with Google's FaceNet deep neural network.","link":"https://github.com/cmusatyalab/openface"},{"text":"Basic digit recognition neural network","link":"https://github.com/joeledenberg/DigitRecognition"},{"text":"Emotion Recognition API Demo - Microsoft","link":"https://www.projectoxford.ai/demo/emotion#detection"},{"text":"Proof of concept for loading Caffe models in TensorFlow","link":"https://github.com/ethereon/caffe-tensorflow"},{"text":"YOLO: Real-Time Object Detection","link":"http://pjreddie.com/darknet/yolo/#webcam"},{"text":"AlphaGo - A replication of DeepMind's 2016 Nature publication, \"Mastering the game of Go with deep neural networks and tree search\"","link":"https://github.com/Rochester-NRT/AlphaGo"}]},{"text":"Contributing","link":"#contributing","contents":[]}]